# Sequence Alignment

Use GSNAP to align mRNA sequences to a genome. These sequences are paired-end reads from fastq files generated by RNA-Seq.

We output Sequence Alignment Map (SAM) format for the aligned reads. We can can parallelize this process using `lofn`.
The many SAM files resulting from this need to be merged into one file, so we use `samtools`. To speed this along and
reduce the output size, we first convert to the compressed, binary format of SAM (BAM) and then merge these files together
into one final BAM file.

Review:

1. - Input: fastq and reference genome
   - Align with `gsnap`
   - Output: aligned reads in SAM format
2. Convert to BAM with `samtools view`
3. merge BAM files with `samtools merge`


## Setup

### Install Docker, Spark, and lofn

[Getting Started](https://github.com/michaetneylon/lofn/docs/)

### Docker Images

build image for gsnap and samtools:

```
cd gsnap_samtools
docker build -t gsnap_samtools .
```

### Data

GSNAP requires a [GMAP](http://research-pub.gene.com/gmap/) generated reference genome and
 fastq files for the input sequence data.

## Usage

See each directory for the different spark master modes and how to setup and run.

## How it Works

Beyond the basic example and some other documentation, here are some explanations of advanced features being used.

### Paired-End Reads

`gsnap` supports aligning paired-end reads by providing the two files, but lofn will only take one rdd as input.
To make this work the two files are read into separate RDDs with index, the read ID, which is used to join the two
 RDDs together with each item indicating the paired reads together. This is able to be partitioned by read ID and then
 each partition is then written out to two files within the map step by using `map_udf`.

### Binary Files

BAM is a compressed binary format. To merge SAM files into a single BAM files, we want all of the separate files to
 be in BAM format first so that our reduce step is associative and commutative.

The `map_binary` allows us to apply a transformation to the RDD which returns a binary file for each partition. The parent
 directory is read into `spark_context.binaryFiles(parent_dir)` to create a new RDD. This is
a suitable input for `reduce_binary` which can apply reduce step with pairs of binary file input.
